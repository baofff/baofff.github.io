<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Home page of Fan Bao">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Fan Bao</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Fan Bao (鲍凡) &nbsp;</h1></div>
        <h3>Co-founder and CTO of ShengShu</h3>  
        <p>
            Email:  <a href="mailto:fan.bao@shengshu.ai">fan.bao@shengshu.ai</a> <br>
            Github: <a href="https://github.com/baofff">baofff</a> <br>
            <a href="https://scholar.google.be/citations?user=AygQYd0AAAAJ&hl=en&oi=ao">[Google Scholar]</a> <br>
        </p>
    </td>

    <td><img src="./files/photo.jpg" border="0" width="200"></td>
</tr></tbody></table>


<h2>Biography</h2>
    <p>I received my Ph.D. degree from <a href="http://ml.cs.tsinghua.edu.cn/index.html">TSAIL Group</a> in the <a href="https://www.cs.tsinghua.edu.cn/csen/">Department of Computer Science and Technology</a>, <a href="https://www.tsinghua.edu.cn">Tsinghua University</a>, advised by <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a> and <a href="https://www.cs.tsinghua.edu.cn/csen/info/1059/4006.htm">Prof. Bo Zhang</a>. Before that, I received my B.S. degree from the Department of Computer Science and Technology, Tsinghua University in July, 2019.</p>

    <p>My research interest includes <strong>machine learning</strong> and <strong>deep learning</strong>. Recently, I am interested in <strong>diffusion models</strong> and its applications, and I have led a series of works on diffusion models, including Analytic-DPM, U-ViT, UniDiffuser, and Vidu.</p>


<h2>Publications</h2>

<ul>
    <br>
    <strong>2024</strong>
    <li>
        <a href=''>Vidu: a Highly Consistent, Dynamic and Skilled Text-to-Video Generator with Diffusion Models</a> <br>
        <strong>Fan Bao</strong>, Chendong Xiang, Gang Yue, Guande He, Hongzhou Zhu, Kaiwen Zheng, Min Zhao, Shilong Liu, Yaole Wang, Jun Zhu <br>
        arXiv preprint <br>
        <a href='https://arxiv.org/abs/2405.04233'>[arXiv]</a>
    </li>
</ul>

<ul>
    <br>
    <strong>2023</strong>
    <li>
        <a href=''>Gaussian Mixture Solvers for Diffusion Models</a> <br>
        Hanzhong Allan Guo, Cheng Lu, <strong>Fan Bao</strong>, Tianyu Pang, Shuicheng Yan, Chao Du, Chongxuan Li
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2311.00941'>[arXiv]</a>
    </li>
    <li>
        <a href=''>Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels</a> <br>
        <font color="#FF0000">Spotlight</font> <br>
        Zebin You, Yong Zhong, <strong>Fan Bao</strong>, Jiacheng Sun, Chongxuan Li, Jun Zhu
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2302.10586'>[arXiv]</a>
    </li>
    <li>
        <a href=''>ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation</a> <br>
        <font color="#FF0000">Spotlight</font> <br>
        Zhengyi Wang, Cheng Lu, Yikai Wang, <strong>Fan Bao</strong>, Chongxuan Li, Hang Su, Jun Zhu <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2305.16213'>[arXiv]</a>
        <a href='https://github.com/thu-ml/prolificdreamer'>[code]</a>
    </li>
    <li>
        <a href=''>One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale</a> <br>
        <strong>Fan Bao</strong>, Shen Nie, Kaiwen Xue, Chongxuan Li, Shi Pu, Yaole Wang, Gang Yue, Yue Cao, Hang Su, Jun Zhu <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2303.06555'>[arXiv]</a>
        <a href='https://github.com/thu-ml/unidiffuser'>[code]</a>
    </li>
    <li>
        <a href=''>Revisiting Discriminative vs. Generative Classifiers: Theory and Implications</a> <br>
        Chenyu Zheng, Guoqiang Wu, <strong>Fan Bao</strong>, Yue Cao, Chongxuan Li, Jun Zhu <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2302.02334'>[arXiv]</a>
    </li>
    <li>
        <a href=''>All are Worth Words: a ViT Backbone for Diffusion Models</a> <br>
        <strong>Fan Bao</strong>, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, Jun Zhu <br>
        Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2209.12152'>[arXiv]</a>
        <a href='https://github.com/baofff/U-ViT'>[code]</a>
    </li>
    <li>
        <a href=''>Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models</a> <br>
        Yong Zhong, Hongtao Liu, Xiaodong Liu, <strong>Fan Bao</strong>, Weiran Shen, Chongxuan Li <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2208.14133'>[arXiv]</a>
    </li>
    <li>
        <a href=''>Equivariant Energy-Guided SDE for Inverse Molecular Design</a> <br>
        <strong>Fan Bao</strong>*, Min Zhao*, Zhongkai Hao, Peiyao Li, Chongxuan Li, Jun Zhu <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2023 <br>
        <a href='https://arxiv.org/abs/2209.15408'>[arXiv]</a>
        <a href='https://github.com/gracezhao1997/EEGSDE'>[code]</a>
    </li>
</ul>

<ul>
    <br>
    <strong>2022</strong>
    <li>
        <a href=''>Why Are Conditional Generative Models Better Than Unconditional Ones?</a> <br>
        <strong>Fan Bao</strong>, Chongxuan Li, Jiacheng Sun, Jun Zhu <br>
        Score-based Model workshop @ <strong>NeurIPS</strong>, 2022 <br>
        <a href='https://arxiv.org/abs/2212.00362'>[arXiv]</a>
    </li>
    <li>
        <a href=''>EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations</a> <br>
        Min Zhao, <strong>Fan Bao</strong>, Chongxuan Li, Jun Zhu <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2022 <br>
        <a href='https://arxiv.org/abs/2207.06635'>[arXiv]</a>
        <a href='https://github.com/ML-GSAI/EGSDE'>[code]</a>
    </li>
    <li>
        <a href=''>DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps</a> <br>
        <font color="#FF0000">Oral (Accept rate~1.7%)</font> <br>
        Cheng Lu, Yuhao Zhou, <strong>Fan Bao</strong>, Jianfei Chen, Chongxuan Li, Jun Zhu <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2022 <br>
        <a href='https://arxiv.org/abs/2206.00927'>[arXiv]</a>
        <a href='https://github.com/LuChengTHU/dpm-solver'>[code]</a>
    </li>
    <li>
        <a href=''>Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models</a> <br>
        <strong>Fan Bao</strong>, Chongxuan Li, Jiacheng Sun, Jun Zhu, Bo Zhang <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2022 <br>
        <a href='https://arxiv.org/abs/2206.07309'>[arXiv]</a>
        <a href='https://github.com/baofff/Extended-Analytic-DPM'>[code]</a>
    </li>
    <li>
        <a href=''>Maximum Likelihood Training for Score-based Diffusion ODEs by High Order Denoising Score Matching</a> <br>
        Cheng Lu, Kaiwen Zheng, <strong>Fan Bao</strong>, Chongxuan Li, Jianfei Chen, Jun Zhu <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2022 <br>
    </li>
    <li>
        <a href='https://openreview.net/pdf?id=0xiJLKH-ufZ'>Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models</a> <br>
        <font color="#FF0000">Outstanding Paper Award (Top 7/3391)</font> <br>
        <strong>Fan Bao</strong>, Chongxuan Li, Jun Zhu, Bo Zhang <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2022 <br>
        <a href='https://arxiv.org/pdf/2201.06503.pdf'>[arXiv]</a>
        <a href='https://github.com/baofff/Analytic-DPM'>[code]</a>
    </li>
</ul>

<ul>
    <br>
    <strong>2021</strong>
    <li>
        <a href='https://proceedings.neurips.cc/paper/2021/file/2406a0a94c80406914ff2f6c9fdd67d5-Paper.pdf'>Stability and Generalization of Bilevel Programming in Hyperparameter Optimization</a> <br>
        <strong>Fan Bao</strong>*, Guoqiang Wu*, Chongxuan Li*, Jun Zhu, Bo Zhang <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2021 <br>
        <a href='https://arxiv.org/pdf/2106.04188.pdf'>[arXiv]</a>
        <a href='https://github.com/baofff/stability_ho'>[code]</a>
    </li>
    <li>
        <a href='http://proceedings.mlr.press/v139/bao21b/bao21b.pdf'>Variational (Gradient) Estimate of the Score Function in Energy-based Latent Variable Models</a> <br>
        <strong>Fan Bao</strong>, Kun Xu, Chongxuan Li, Lanqing Hong, Jun Zhu, Bo Zhang <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2021 <br>
        <a href='https://arxiv.org/pdf/2010.08258.pdf'>[arXiv]</a>
        <a href='https://github.com/baofff/VaGES'>[code]</a>
    </li>
</ul>

<ul>
    <br>
    <strong>2020</strong>
    <li>
        <a href='https://proceedings.neurips.cc/paper/2020/file/d25a34b9c2a87db380ecd7f7115882ec-Paper.pdf'>Bi-level Score Matching for Learning Energy-based Latent Variable Models</a> <br>
        <strong>Fan Bao</strong>*, Chongxuan Li*, Kun Xu, Hang Su, Jun Zhu, Bo Zhang <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2020 <br>
        <a href='https://arxiv.org/pdf/2010.07856.pdf'>[arXiv]</a>
        <a href='https://github.com/baofff/BiSM'>[code]</a>
    </li>
</ul>


<h2>Honors & Awards</h2>
<li><strong>Huawei Scholarship</strong>, 2023</li>
<li><strong>LongHu Scholarship · Excellence Award</strong>, 2023</li>
<li><strong>ZhongShimo Scholarship</strong>, 2022</li>
<li><strong>China National Scholarship</strong>, 2022</li>
<li><strong>ByteDance Scholarship</strong>, 2022.10</li>
<li><strong>Huawei Innovation Pioneer First Prize</strong>, 2022</li>
<li><strong>International Conference on Learning Representations (ICLR) Outstanding Paper Awards</strong>, 2022</li>

<!-- <li><strong>Yang Huiyan Scholarship</strong>, 2021.10</li> -->


<!-- <h2>Services</h2>
<strong>Reviewer for</strong>:<br>
<strong>NeurIPS</strong> 2021, 2022<br>
<strong>ICML</strong> 2021, 2022<br>
<strong>ICLR</strong> 2022, 2023<br>
<strong>CVPR</strong> 2023<br> -->


<h2>Invited Talks</h2>

<strong>Large Multi-Modal Generative Models, CCAI 2023</strong>, 2023.7 <br>

<strong>Diffusion Probabilistic Models: Foundations, Fast Inference and Controllable Generation, BAAI Large Model Innovation Forum 2022</strong>, 2022.12 <br>

<strong>Diffusion Probabilistic Models: Theory and Applications, Shanghai Artificial Intelligence Laboratory Xingqi Talk</strong>, 2022.11 <br>

<strong>Diffusion Probabilistic Models: Theory and Applications, Jiqi Zhixin</strong>, 2022.11 <br>

<strong>Applications of Diffusion Models, ByteDance</strong>, 2022.5 <a href="https://ml.cs.tsinghua.edu.cn/~fanbao/Application-DPM.pdf">[slide]</a><br>


<!-- <h2>Teaching</h2>
2021 Spring, TA in <strong>Statistical Learning Theory and Applications</strong>, instructed by <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a><br>
2021 Spring, TA in <strong>Deep Learning</strong>, instructed by <a href="http://www.xlhu.cn/">Prof. Xiaolin Hu</a> and <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a><br>
2019 Fall, TA in <strong>Calculus</strong>, instructed by Prof. Jianlian Cui</a><br> -->


</div>

<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2022 Fan Bao

</body>

</html>
